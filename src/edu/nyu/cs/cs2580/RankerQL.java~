package edu.nyu.cs.cs2580;

import java.util.Collections;
import java.util.Vector;

import edu.nyu.cs.cs2580.QueryHandler.CgiArguments;
import edu.nyu.cs.cs2580.SearchEngine.Options;

// Query Likelihood (language model)
// Smoothing : Jelinek-Mercer smoothing
// lambda : 0.50

class RankerQL extends Ranker {

    public RankerQL(Options options,
		    CgiArguments arguments, Indexer indexer) {
	super(options, arguments, indexer);
	System.out.println("Using Ranker: " + this.getClass().getSimpleName());
    }

    @Override
	public Vector<ScoredDocument> runQuery(Query query, int numResults) {    
	Vector<ScoredDocument> all = new Vector<ScoredDocument>();
	for (int i = 0; i < _indexer.numDocs(); ++i) {
	    all.add(scoreDocument(query, i));
	}
	Collections.sort(all, Collections.reverseOrder());
	Vector<ScoredDocument> results = new Vector<ScoredDocument>();
	for (int i = 0; i < all.size() && i < numResults; ++i) {
	    results.add(all.get(i));
	}
	return results;
    }

    private ScoredDocument scoreDocument(Query query, int did) {
	// Process the raw query into tokens.
	query.processQuery();

	// Get the document tokens.
	Document doc = _indexer.getDoc(did);
	Vector<String> docTokens = ((DocumentFull) doc).getConvertedTitleTokens();

	// Variables
	double score=1.0, lambda=0.50;

	// Score the document.
	/*
	  Vector<String> dv = d.get_title_vector();
	  dv.addAll(d.get_body_vector());
	*/
	for(String queryToken : query._tokens){
	    score *= ((1-lambda)*((double)d.termFrequencyInDoc(queryToken)
				  / (double)dv.size())
		      + (lambda)*((double)Document.termFrequency(queryToken)
				  / (double)Document.termFrequency()));
	}

	return new ScoredDocument(doc, score);
    }
    
    private void normalize(Vector<Double> _weights){
	double sum = 0.0;
	for(int i=0; i<_weights.size(); i++)
	    sum += _weights.get(i) * _weights.get(i);
	if(sum==0)  return;
	sum = Math.sqrt(sum);
	for(int i=0; i<_weights.size(); i++){
	    double newWeight = _weights.get(i)/sum;
	    _weights.set(i, newWeight);
	}
    }
}
